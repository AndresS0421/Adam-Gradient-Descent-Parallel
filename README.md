# Adam Gradient Descent Parallel

A C++ implementation comparing sequential and parallel Adam optimization algorithms using OpenMP for high-dimensional optimization problems.

## ğŸ“‹ Overview

This project implements and compares:
- **Adam Sequential**: Traditional Adam optimizer processing points one by one
- **Adam Parallel**: Parallel Adam optimizer using OpenMP to process multiple points simultaneously

The implementation uses a high-dimensional Rosenbrock-like objective function to demonstrate the performance benefits of parallelization.

## ğŸš€ Features

- **OpenMP Parallelization**: Multi-threaded optimization using OpenMP
- **High-Dimensional Optimization**: Supports optimization problems with 20+ parameters
- **Performance Comparison**: Detailed timing analysis between sequential and parallel implementations
- **Data Visualization**: Python scripts for plotting results and performance metrics
- **Cross-Platform**: Compatible with macOS, Linux, and Windows

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.cpp              # Main program with timing experiments
â”œâ”€â”€ optimizer.hpp         # Adam optimizer class definition
â”œâ”€â”€ optimizer.cpp         # Adam optimizer implementation with OpenMP
â”œâ”€â”€ adam_parallel.hpp     # Parallel Adam optimizer for batch processing
â”œâ”€â”€ dataset.hpp           # Objective functions and gradients
â”œâ”€â”€ plot_results.py       # Python visualization script
â”œâ”€â”€ results/              # Generated results directory
â”‚   â”œâ”€â”€ experiments.csv   # Optimization trajectory data
â”‚   â”œâ”€â”€ timing.csv        # Execution time measurements
â”‚   â””â”€â”€ plots/            # Generated visualization plots
â””â”€â”€ README.md             # This file
```

## ğŸ› ï¸ Requirements

### C++ Compilation
- **GCC 9+** or **Clang 10+** with OpenMP support
- **OpenMP** library
- **C++17** standard support

### Python Visualization
- Python 3.7+
- pandas
- matplotlib
- seaborn

## ğŸ”§ Installation & Compilation

### macOS (using Homebrew)
```bash
# Install OpenMP
brew install libomp

# Compile with Clang
clang++ -Xpreprocessor -fopenmp -lomp -O2 -std=c++17 -o main main.cpp optimizer.cpp

# Or compile with GCC
g++-15 -fopenmp -O2 -std=c++17 -o main main.cpp optimizer.cpp
```

### Linux
```bash
# Install OpenMP (Ubuntu/Debian)
sudo apt-get install libomp-dev

# Compile
g++ -fopenmp -O2 -std=c++17 -o main main.cpp optimizer.cpp
```

## ğŸƒâ€â™‚ï¸ Usage

### Run the optimization experiments
```bash
./main
```

This will generate:
- `results/experiments.csv`: Optimization trajectories
- `results/timing.csv`: Execution time measurements

### Generate visualizations
```bash
python plot_results.py
```

This creates plots in `results/plots/`:
- Loss curves comparison
- Execution time analysis
- Performance metrics

## ğŸ“Š Results

The program compares performance across different learning rates:
- **0.1**: High learning rate
- **0.01**: Medium learning rate  
- **0.001**: Low learning rate

### Expected Performance Gains
- **Parallel processing** typically shows 2-4x speedup on multi-core systems
- **Higher dimensional problems** (20+ parameters) benefit more from parallelization
- **Batch processing** of multiple optimization points simultaneously

## ğŸ”¬ Technical Details

### Adam Optimizer
- **Adaptive learning rates** for each parameter
- **Momentum** (Î²â‚ = 0.9) for gradient smoothing
- **RMSprop** (Î²â‚‚ = 0.999) for learning rate adaptation
- **Bias correction** for unbiased estimates

### Parallelization Strategy
- **OpenMP parallel for loops** for parameter updates
- **Static scheduling** for even work distribution
- **Thread-safe** operations with private variables
- **Batch processing** for multiple optimization points

### Objective Function
High-dimensional Rosenbrock function:
```
f(x) = Î£[100(x_{i+1} - x_iÂ²)Â² + (1 - x_i)Â²]
```
- **Non-convex** optimization landscape
- **Multiple local minima**
- **Challenging** for gradient-based methods

## ğŸ“ˆ Performance Analysis

The visualization script provides:
- **Loss curves** showing convergence behavior
- **Execution time** comparison between methods
- **Speedup analysis** for parallel implementation
- **Learning rate** sensitivity analysis

## ğŸ¯ Educational Value

This project demonstrates:
- **Parallel programming** concepts with OpenMP
- **Optimization algorithms** implementation
- **Performance measurement** and analysis
- **Scientific computing** best practices
- **Data visualization** for research results

## ğŸ“ License

This project is created for educational purposes as part of a Parallel Programming course.

## ğŸ‘¨â€ğŸ’» Authors

**AndrÃ©s SolÃ­s**  
**Alonso Flores**  
**Joel GarcÃ­a**

Universidad de Colima - 7Â° Semestre\
ProgramaciÃ³n Paralela - 2Â° Parcial

---

*For questions or issues, please refer to the course materials or contact the instructor.*